{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.pipeline\n",
    "from cross_validation import train_models_and_calc_scores_for_n_fold_cv\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir='./data_reviews'\n",
    "\n",
    "# # read in training data\n",
    "# x_train_df = pd.read_csv(os.path.join(data_dir, 'x_train.csv'))\n",
    "# y_train_df = pd.read_csv(os.path.join(data_dir, 'y_train.csv'))\n",
    "\n",
    "# # create a list of all reviews\n",
    "# x_text_list = x_train_df.values[:,1]\n",
    "# x_text_list = x_text_list.tolist()\n",
    "\n",
    "# tokens = [word_tokenize(review.lower()) for review in x_text_list]\n",
    "\n",
    "# word_2_vec = Word2Vec(tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
    "# print(x_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # takes average of vector for all words in a sentence\n",
    "# def average_word_vectors(words, model, vocabulary, num_features):\n",
    "#     feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
    "#     nwords = 0.\n",
    "    \n",
    "#     for word in words:\n",
    "#         if word in vocabulary: \n",
    "#             nwords = nwords + 1.\n",
    "#             feature_vector = np.add(feature_vector, model.wv[word])\n",
    "    \n",
    "#     if nwords:\n",
    "#         feature_vector = np.divide(feature_vector, nwords)\n",
    "        \n",
    "#     return feature_vector\n",
    "\n",
    "# # list of vectors\n",
    "# feature_vectors = [average_word_vectors(review, word_2_vec, word_2_vec.wv.key_to_index, 100) for review in x_text_list]\n",
    "# x_train_matrix = np.stack(feature_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='./data_reviews'\n",
    "\n",
    "# read in training data\n",
    "x_train_df = pd.read_csv(os.path.join(data_dir, 'x_train.csv'))\n",
    "y_train_df = pd.read_csv(os.path.join(data_dir, 'y_train.csv'))\n",
    "\n",
    "# create a list of all reviews\n",
    "x_text_list = x_train_df.values[:,1]\n",
    "x_text_list = x_text_list.tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "# fit_transform will make its own vocabular from the text\n",
    "x = vectorizer.fit_transform(x_text_list)  \n",
    "x_train_matrix = x.toarray()\n",
    "\n",
    "# export vocabulary\n",
    "vocabulary = vectorizer.vocabulary_\n",
    "with open('vocab2.pkl','wb') as f:\n",
    "    pickle.dump(vocabulary,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export vocabulary\n",
    "# with open('word2vec_model.pkl','wb') as f:\n",
    "#     pickle.dump(word_2_vec,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# C is hyperparam for regularization\n",
    "param_grid = {}\n",
    "\n",
    "# by default,um folds is 5\n",
    "search = HalvingGridSearchCV(clf, param_grid,cv=5, random_state=0).fit(x_train_matrix, y_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(search.best_params_)\n",
    "#print(search.cv_results_['split0_test_score'])\n",
    "#print(search.cv_results_['params'])\n",
    "\n",
    "# indices = []\n",
    "# for index, dict in enumerate(search.cv_results_['params']):\n",
    "#     if dict['tol'] == search.best_params_['tol']:\n",
    "#         indices.append(index)\n",
    "\n",
    "# print(indices)\n",
    "# for idx in indices:\n",
    "#     print(search.cv_results_['params'][idx])\n",
    "\n",
    "#indices = indices[0:17]\n",
    "# test_scores = []\n",
    "# train_scores = []\n",
    "# test_split0, train_split0, test_split1, train_split1, test_split2, train_split2, test_split3, train_split3, test_split4, train_split4 = ([] for i in range(10))\n",
    "# for idx in indices:\n",
    "#     test_scores.append(search.cv_results_['mean_test_score'][idx])\n",
    "#     train_scores.append(search.cv_results_['mean_train_score'][idx])\n",
    "#     test_split0.append(search.cv_results_['split0_test_score'][idx])\n",
    "#     train_split0.append(search.cv_results_['split0_train_score'][idx])\n",
    "#     test_split1.append(search.cv_results_['split1_test_score'][idx])\n",
    "#     train_split1.append(search.cv_results_['split1_train_score'][idx])\n",
    "#     test_split2.append(search.cv_results_['split2_test_score'][idx])\n",
    "#     train_split2.append(search.cv_results_['split2_train_score'][idx])\n",
    "#     test_split3.append(search.cv_results_['split3_test_score'][idx])\n",
    "#     train_split3.append(search.cv_results_['split3_train_score'][idx])\n",
    "#     test_split4.append(search.cv_results_['split4_test_score'][idx])\n",
    "#     train_split4.append(search.cv_results_['split4_train_score'][idx])\n",
    "\n",
    "# print(test_scores)\n",
    "# print(train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "y_train_labels = y_train_df\n",
    "model.fit(x_train_matrix, y_train_labels.values.ravel())\n",
    "\n",
    "# save classifiers to pkl files\n",
    "with open('prob2model.pkl','wb') as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  np.logspace(-10,6,17)\n",
    "plt.plot(x, train_scores, label=\"train scores\")\n",
    "plt.plot(x, test_scores, label=\"test scores\")\n",
    "plt.scatter(x, test_split0, color=\"orange\")\n",
    "plt.scatter(x, test_split1, color=\"orange\")\n",
    "plt.scatter(x, test_split2, color=\"orange\")\n",
    "plt.scatter(x, test_split3, color=\"orange\")\n",
    "plt.scatter(x, test_split4, color=\"orange\")\n",
    "plt.scatter(x, train_split0, color=\"blue\")\n",
    "plt.scatter(x, train_split1, color=\"blue\")\n",
    "plt.scatter(x, train_split2, color=\"blue\")\n",
    "plt.scatter(x, train_split3, color=\"blue\")\n",
    "plt.scatter(x, train_split4, color=\"blue\")\n",
    "plt.legend()\n",
    "plt.title(\"Hyperparameter Search: scores vs. C\")\n",
    "plt.xlabel(\"Inverse Regularization Strength: C\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train logistic regression with the selected best params\n",
    "classifier = LogisticRegression(C=search.best_params_[\"C\"], tol=search.best_params_[\"tol\"], solver=search.best_params_[\"solver\"]) \n",
    "classifier.fit(x_train_NV, y_train_df.values.ravel())\n",
    "\n",
    "# save classifiers to pkl files\n",
    "with open('testing2.pkl','wb') as f:\n",
    "    pickle.dump(classifier,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train_df = np.array(y_train_df)\n",
    "y_train_df.shape\n",
    "y_train_df = y_train_df.reshape((2400,))\n",
    "print(y_train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_df.to_numpy().shape)\n",
    "print(x_train_NV.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "        \n",
    "cv_train_err_list = []\n",
    "cv_valid_err_list = []\n",
    "# pipeline = sklearn.pipeline.Pipeline(\n",
    "#     steps = [('Log regr', LogisticRegression(C= 1e-10, penalty='l1', tol=1e-7))])\n",
    "\n",
    "#y_train_df = np.array(y_train_df)\n",
    "length = 2400\n",
    "split = 0.8\n",
    "split_spot = 1920\n",
    "rand_indicies = np.random.permutation(length)\n",
    "x_train_array = x_train_df.to_numpy()\n",
    "x_train_text = x_train_array[rand_indicies]\n",
    "x_train_NV = x_train_NV[rand_indicies]\n",
    "y_train_df = y_train_df[rand_indicies]\n",
    "\n",
    "x_train_split = x_train_NV[0:split_spot]\n",
    "y_train_split = y_train_df[0:split_spot]\n",
    "x_test_split = x_train_NV[split_spot:2400]\n",
    "y_test_split = y_train_df[split_spot:2400]\n",
    "\n",
    "pipeline = LogisticRegression(C= 0.1, penalty='l2', tol=1e-5)\n",
    "\n",
    "pipeline.fit(x_train_split, y_train_split)\n",
    "\n",
    "preds = pipeline.predict(x_test_split)\n",
    "y_proba_preds = pipeline.predict_proba(x_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives = np.intersect1d(np.where(preds == 1)[0], np.where(y_test_split == 0)[0]) + 1920\n",
    "false_negatives = np.intersect1d(np.where(preds == 0)[0], np.where(y_test_split == 1)[0]) + 1920\n",
    "print(false_negatives)\n",
    "# print(len(false_positives))\n",
    "# print(x_train_df.shape)\n",
    "# for idx in false_negatives:\n",
    "#     print(x_train_df[idx])\n",
    "for idx in false_negatives:\n",
    "    print(x_train_text[idx])\n",
    "    print(y_train_df[idx])\n",
    "    print(preds[idx - 1920])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(false_positives))\n",
    "# print(x_train_df.shape)\n",
    "# for idx in false_negatives:\n",
    "#     print(x_train_df[idx])\n",
    "for idx in false_positives:\n",
    "    print(x_train_text[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute AUROC score\n",
    "auroc_score = roc_auc_score( y_test_split, y_proba_preds[:,1]) \n",
    "print(auroc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_train_err_list)\n",
    "print(cv_valid_err_list)\n",
    "# for C= 1e-10, penalty='l2', tol=1e-7\n",
    "#   train_err = 0.43073043\n",
    "#   valid_err = 0.52891713\n",
    "# for C= 1e6, penalty='l2', tol=1e-7\n",
    "#   train_err = 0.07053015\n",
    "#   valid_err = 0.48599428\n",
    "# for C= 1, penalty='l2', tol=1e-3\n",
    "#   train_err = 0.19003116\n",
    "#   valid_err = 0.44722232\n",
    "# for C= 10-5, penalty='l2', tol=1e-1\n",
    "#   train_err = 0.12028722\n",
    "#   valid_err = 0.4509112"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs135_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
